{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2e54e0",
   "metadata": {},
   "source": [
    "# D&D Gameplay Log Analysis Tutorial\n",
    "\n",
    "This notebook demonstrates how to analyze Dungeons & Dragons gameplay logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a2339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created plots directory: plots\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import analysis.data_loading as dl\n",
    "import analysis.basic_metrics as basic\n",
    "import analysis.creativity_metrics as creativity\n",
    "import analysis.cohesion_metrics as cohesion\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.color_palette(\"mako\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Create Plots directory\n",
    "plots_dir = Path('plots')\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "print(f\"Created plots directory: {plots_dir}\")\n",
    "\n",
    "# Helper function for saving plots\n",
    "def save_plot(filename):\n",
    "    filepath = plots_dir / filename\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a3a96",
   "metadata": {},
   "source": "# Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c81dc",
   "metadata": {},
   "outputs": [],
   "source": "# === CONFIGURATION ===\n\n# Base campaign names to analyze\nCAMPAIGN_BASE_NAMES = [\n    '1262-firedeath-must-die-closed-play-by-post-open-ogg',\n    '3135-the-head-of-the-serpent',\n    '10391-guardians-of-gridori',\n    '20049-age-of-death',\n    '89221-banhaven-academy-year-1',\n    '90630-firecat5s-dragon-of-icespire-peak',\n    '7426-serpent-isle-private-campaign',\n]\n\n# LLM game filters\nLLM_FILTER = {\n    'model': ['gpt-4o', 'gemini-1.5-pro', 'claude-3-7-sonnet-latest'],\n    'campaign_name': CAMPAIGN_BASE_NAMES,\n    'include_player_personalities': [True, False],\n    'year': 2025,\n    'scratchpad': True,\n}\n\n# Category grouping - which metadata fields to group by for aggregation\nCATEGORY_FIELDS = ['model', 'include_player_personalities']\n\n# Analysis parameters\nMESSAGES_PER_SESSION = 5\nFORCE_REFRESH = False\n\n# Output\nOUTPUT_DIR = Path('plots')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f993b99",
   "metadata": {},
   "outputs": [],
   "source": "# === DATA LOADING ===\n\n# Load human campaigns\ndfs_human = dl.load_campaigns(\n    CAMPAIGN_BASE_NAMES,\n    messages_per_session=MESSAGES_PER_SESSION\n)\n\n# Load LLM campaigns with filtering\ndfs_llm = dl.load_campaigns(\n    'llm',\n    messages_per_session=MESSAGES_PER_SESSION,\n    filter_by=LLM_FILTER\n)\n\n# Combine DataFrames\ndfs = {**dfs_human, **dfs_llm}\n\nprint(f\"Loaded {len(dfs_human)} human campaigns, {len(dfs_llm)} LLM campaigns\")\nprint(f\"Total: {len(dfs)} campaigns\")"
  },
  {
   "cell_type": "markdown",
   "id": "9a10fe79",
   "metadata": {},
   "source": [
    "# Calculate game log analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475360e2",
   "metadata": {},
   "outputs": [],
   "source": "# === METRICS CALCULATION ===\n\nbasic_metrics = basic.analyze_basic_metrics(dfs, force_refresh=FORCE_REFRESH)\n\ncreativity_metrics = creativity.analyze_creativity(dfs, force_refresh=FORCE_REFRESH)\n\ncohesion_metrics = cohesion.analyze_cohesion(\n    dfs,\n    messages_per_session=MESSAGES_PER_SESSION,\n    force_refresh=FORCE_REFRESH\n)"
  },
  {
   "cell_type": "markdown",
   "id": "d8238bbc",
   "metadata": {},
   "source": "# Helper Functions"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848fd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data,\n",
    "                   colors=None,\n",
    "                   edgecolor='none',\n",
    "                   alpha=0.5,\n",
    "                   colormap='viridis',\n",
    "                   xlabel=None,\n",
    "                   bins=None,\n",
    "                   log_bins=False,\n",
    "                   log_y=False,\n",
    "                   figsize=(4, 4),\n",
    "                   ylabel=\"Counts\",\n",
    "                   labels=None):\n",
    "    \"\"\"\n",
    "    Plot histogram(s) with colors evenly spaced across a colormap.\n",
    "    \n",
    "    Parameters:\n",
    "    data: Single array/list OR list of arrays/lists to plot as histograms\n",
    "    colors (list): Specific colors (if None, uses colormap spacing)\n",
    "    edgecolor (str): Edge color for bars (default: 'none')\n",
    "    alpha (float): Transparency level (default: 0.5)\n",
    "    colormap (str): Colormap name (default: 'viridis')\n",
    "    xlabel (str): X-axis label (default: None, no label)\n",
    "    bins: Number of bins (default: None uses matplotlib default)\n",
    "    log_bins (bool): Use log-spaced bins and log x-axis (default: False)\n",
    "    log_y (bool): Use log scale for y-axis (default: False)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Auto-detect if data is a single array or list of arrays\n",
    "    try:\n",
    "        if isinstance(data[0], (list, np.ndarray)):\n",
    "            data_list = data  # Already a list of arrays\n",
    "        else:\n",
    "            data_list = [data]  # Single array, wrap it in a list\n",
    "    except:\n",
    "        data_list = [data]\n",
    "\n",
    "    # Remove NaN values from all datasets\n",
    "    clean_data_list = []\n",
    "    for dataset in data_list:\n",
    "        clean_dataset = np.array(dataset)[~np.isnan(np.array(dataset))]\n",
    "        clean_data_list.append(clean_dataset)\n",
    "\n",
    "    n_plots = len(clean_data_list)\n",
    "\n",
    "    if colors is None:\n",
    "        cmap = cm.get_cmap(colormap)\n",
    "        if n_plots == 1:\n",
    "            colors = [cmap(0.5)]\n",
    "        else:\n",
    "            colors = [cmap(i / (n_plots - 1)) for i in range(n_plots)]\n",
    "\n",
    "    # Calculate common bins across all datasets (now NaN-free)\n",
    "    all_data = np.concatenate(clean_data_list)\n",
    "\n",
    "    if len(all_data) == 0:\n",
    "        raise ValueError(\"All data contains only NaN values\")\n",
    "\n",
    "    if log_bins:\n",
    "        # Filter out zeros and negatives for log scale\n",
    "        positive_data = all_data[all_data > 0]\n",
    "        if len(positive_data) == 0:\n",
    "            raise ValueError(\"log_bins=True requires positive values in data\")\n",
    "\n",
    "        min_val = np.min(positive_data)\n",
    "        max_val = np.max(positive_data)\n",
    "\n",
    "        if bins is None:\n",
    "            bins = 50  # Default number of log bins\n",
    "\n",
    "        common_bins = np.logspace(np.log10(min_val), np.log10(max_val), bins)\n",
    "    else:\n",
    "        # Linear bins\n",
    "        if bins is None:\n",
    "            bins = 50  # Default number of bins\n",
    "\n",
    "        min_val = np.min(all_data)\n",
    "        max_val = np.max(all_data)\n",
    "        common_bins = np.linspace(min_val, max_val, bins)\n",
    "\n",
    "    # Plot all histograms with the same bins (NaN-free data)\n",
    "    for i, dataset in enumerate(clean_data_list):\n",
    "        if labels is not None:\n",
    "            label = labels[i]\n",
    "        else:\n",
    "            label = None\n",
    "        plt.hist(dataset,\n",
    "                 bins=common_bins,\n",
    "                 color=colors[i],\n",
    "                 edgecolor=edgecolor,\n",
    "                 alpha=alpha,\n",
    "                 label=label)\n",
    "\n",
    "    # Set axis scales\n",
    "    if log_bins:\n",
    "        plt.xscale('log')\n",
    "\n",
    "    if log_y:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel, clip_on=False)\n",
    "    # Style axes\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(colors='#4a4a4a', width=0.5)\n",
    "    ax.spines['left'].set_color('#4a4a4a')\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_color('#4a4a4a')\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    ax.xaxis.label.set_color('#4a4a4a')\n",
    "    ax.yaxis.label.set_color('#4a4a4a')"
   ]
  },
  {
   "cell_type": "code",
   "id": "jel4im246v",
   "source": "# === CATEGORIZATION FUNCTIONS ===\n\ndef categorize_campaigns(campaign_names, category_fields):\n    \"\"\"\n    Categorize campaigns based on metadata fields.\n\n    Args:\n        campaign_names: List of campaign names (keys from dfs)\n        category_fields: List of metadata fields to use for grouping\n                        e.g., ['model', 'include_player_personalities']\n\n    Returns:\n        Dict mapping category_name -> list of campaign names\n        e.g., {'human': [...], 'model:gpt-4o, include_player_personalities:True': [...]}\n    \"\"\"\n    # Load metadata index (relative to tutorials/ directory)\n    metadata_index_path = Path('../data/llm-games/metadata_index.json')\n    with open(metadata_index_path) as f:\n        metadata_index = json.load(f)\n\n    categories = {'human': []}\n\n    for name in campaign_names:\n        # Check if it's in metadata_index (LLM game)\n        if name in metadata_index:\n            metadata = metadata_index[name]\n\n            # Build category key as \"field1:value1, field2:value2\"\n            parts = []\n            for field in category_fields:\n                value = metadata.get(field)\n                if value is not None:\n                    parts.append(f\"{field}:{value}\")\n\n            category_key = ', '.join(parts) if parts else 'llm_other'\n\n            if category_key not in categories:\n                categories[category_key] = []\n            categories[category_key].append(name)\n        else:\n            # Human campaign (not in LLM metadata index)\n            categories['human'].append(name)\n\n    return categories\n\n\ndef aggregate_by_category(metric_data, campaign_names, categories, category_order=None):\n    \"\"\"\n    Aggregate metric data by category.\n\n    Args:\n        metric_data: List of metric arrays, one per campaign (in same order as campaign_names)\n        campaign_names: List of campaign names corresponding to metric_data\n        categories: Dict from categorize_campaigns()\n        category_order: Optional list specifying order of categories in output\n\n    Returns:\n        Tuple of (aggregated_data, category_order) where aggregated_data is a list of \n        concatenated arrays, one per category\n    \"\"\"\n    # Build name -> index mapping\n    name_to_idx = {name: i for i, name in enumerate(campaign_names)}\n\n    # Default order: human first, then sorted\n    if category_order is None:\n        category_order = ['human'] + sorted(k for k in categories.keys() if k != 'human')\n\n    result = []\n    for cat in category_order:\n        cat_names = categories.get(cat, [])\n        if cat_names:\n            cat_data = [metric_data[name_to_idx[n]] for n in cat_names if n in name_to_idx]\n            result.append(np.concatenate(cat_data) if cat_data else np.array([]))\n        else:\n            result.append(np.array([]))\n\n    return result, category_order",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50878e82",
   "metadata": {},
   "outputs": [],
   "source": "# === DATA PREPARATION ===\n\n# Get ordered campaign names\ncampaign_names = list(dfs.keys())\n\n# Categorize campaigns using metadata\ncategories = categorize_campaigns(campaign_names, CATEGORY_FIELDS)\n\n# Print category summary\nprint(\"Campaign categories:\")\nfor cat, names in categories.items():\n    print(f\"  {cat}: {len(names)} campaigns\")\n\n# Build metric lists (in same order as campaign_names)\ntime_intervals_data = []\npost_len_data = []\nsbert_post_distances = []\nsbert_session_creativity = []\ncohesion_session_scores = []\n\nfor name in campaign_names:\n    # Time intervals\n    time_intervals_data.append(\n        basic_metrics[name]['time_intervals_overall']['overall']['intervals_data']\n    )\n    \n    # Post lengths\n    post_len_data.append(\n        basic_metrics[name]['post_lengths_overall']['overall']['word_counts_data']\n    )\n    \n    # Semantic distances (creativity 2)\n    sbert_post_distances.append(\n        np.array(creativity_metrics[name]['semantic_distances'])\n    )\n    \n    # Session novelty (creativity 1)\n    sbert_session_creativity.append(\n        np.array(creativity_metrics[name]['session_novelty'][['mean_distance']])\n    )\n    \n    # Cohesion scores\n    if cohesion_metrics[name] is not None:\n        cohesion_session_scores.append(\n            np.array(cohesion_metrics[name]['session_cohesion_scores'])\n        )\n    else:\n        cohesion_session_scores.append(np.array([np.nan]))"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d65718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_histograms(data,\n",
    "                               colors=None,\n",
    "                               edgecolor='none',\n",
    "                               alpha=0.5,\n",
    "                               colormap='viridis',\n",
    "                               xlabel=None,\n",
    "                               bins=None,\n",
    "                               log_bins=False,\n",
    "                               log_y=False,\n",
    "                               labels=None,\n",
    "                               figsize=None,\n",
    "                               ylabel=\"Counts\"):\n",
    "    \"\"\"\n",
    "    Plot comparison histograms with the first dataset appearing in every subplot,\n",
    "    and each subsequent dataset compared against it in separate vertical subplots.\n",
    "    \n",
    "    Parameters:\n",
    "    data: List of arrays/lists (must have at least 2 datasets)\n",
    "    colors (list): Specific colors (if None, uses colormap spacing)\n",
    "    edgecolor (str): Edge color for bars (default: 'none')\n",
    "    alpha (float): Transparency level (default: 0.5)\n",
    "    colormap (str): Colormap name (default: 'viridis')\n",
    "    xlabel (str): X-axis label (default: None, no label)\n",
    "    bins: Number of bins (default: None uses matplotlib default)\n",
    "    log_bins (bool): Use log-spaced bins and log x-axis (default: False)\n",
    "    log_y (bool): Use log scale for y-axis (default: False)\n",
    "    labels (list): Labels for each dataset (default: None)\n",
    "    figsize (tuple): Figure size (width, height). If None, auto-calculated\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input\n",
    "    if not isinstance(data, list) or len(data) < 2:\n",
    "        raise ValueError(\"data must be a list with at least 2 datasets\")\n",
    "\n",
    "    # Auto-detect if data contains arrays or single values\n",
    "    data_list = []\n",
    "    for dataset in data:\n",
    "        try:\n",
    "            if isinstance(dataset[0], (list, np.ndarray)):\n",
    "                data_list.append(dataset)\n",
    "            else:\n",
    "                data_list.append(dataset)\n",
    "        except:\n",
    "            data_list.append(dataset)\n",
    "\n",
    "    # Remove NaN values from all datasets\n",
    "    clean_data_list = []\n",
    "    for dataset in data_list:\n",
    "        clean_dataset = np.array(dataset)[~np.isnan(np.array(dataset))]\n",
    "        clean_data_list.append(clean_dataset)\n",
    "\n",
    "    if any(len(dataset) == 0 for dataset in clean_data_list):\n",
    "        raise ValueError(\"One or more datasets contain only NaN values\")\n",
    "\n",
    "    n_datasets = len(clean_data_list)\n",
    "    n_subplots = n_datasets - 1  # Number of comparison subplots\n",
    "\n",
    "    # Set up figure size\n",
    "    if figsize is None:\n",
    "        figsize = (8, 3 * n_subplots)  # 3 inches height per subplot\n",
    "\n",
    "    fig, axes = plt.subplots(n_subplots, 1, figsize=figsize, sharex=True)\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    # Handle case where there's only one comparison (single axis)\n",
    "    if n_subplots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Set up colors\n",
    "    if colors is None:\n",
    "        cmap = cm.get_cmap(colormap)\n",
    "        if n_datasets == 1:\n",
    "            colors = [cmap(0.5)]\n",
    "        else:\n",
    "            colors = [cmap(i / (n_datasets - 1)) for i in range(n_datasets)]\n",
    "\n",
    "    # Calculate common bins across all datasets\n",
    "    all_data = np.concatenate(clean_data_list)\n",
    "\n",
    "    if log_bins:\n",
    "        # Filter out zeros and negatives for log scale\n",
    "        positive_data = all_data[all_data > 0]\n",
    "        if len(positive_data) == 0:\n",
    "            raise ValueError(\"log_bins=True requires positive values in data\")\n",
    "\n",
    "        min_val = np.min(positive_data)\n",
    "        max_val = np.max(positive_data)\n",
    "\n",
    "        if bins is None:\n",
    "            bins = 50\n",
    "\n",
    "        common_bins = np.logspace(np.log10(min_val), np.log10(max_val), bins)\n",
    "    else:\n",
    "        # Linear bins\n",
    "        if bins is None:\n",
    "            bins = 50\n",
    "\n",
    "        min_val = np.min(all_data)\n",
    "        max_val = np.max(all_data)\n",
    "        common_bins = np.linspace(min_val, max_val, bins)\n",
    "\n",
    "    # Reference dataset (first one)\n",
    "    reference_data = clean_data_list[0]\n",
    "    reference_color = colors[0]\n",
    "    reference_label = labels[0] if labels is not None else \"Reference\"\n",
    "\n",
    "    # Plot each comparison\n",
    "    for i in range(n_subplots):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Current comparison dataset (i+1 because we skip the reference)\n",
    "        comparison_data = clean_data_list[i + 1]\n",
    "        comparison_color = colors[i + 1]\n",
    "        comparison_label = labels[\n",
    "            i + 1] if labels is not None else f\"Dataset {i + 1}\"\n",
    "\n",
    "        # Plot reference histogram (same in every subplot)\n",
    "        ax.hist(reference_data,\n",
    "                bins=common_bins,\n",
    "                color=reference_color,\n",
    "                edgecolor=edgecolor,\n",
    "                alpha=alpha,\n",
    "                label=reference_label)\n",
    "\n",
    "        # Plot comparison histogram\n",
    "        ax.hist(comparison_data,\n",
    "                bins=common_bins,\n",
    "                color=comparison_color,\n",
    "                edgecolor=edgecolor,\n",
    "                alpha=alpha,\n",
    "                label=comparison_label)\n",
    "\n",
    "        # Set axis scales\n",
    "        if log_bins:\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        if log_y:\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "        # Style the subplot\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "        # Only add ylabel to the middle subplot\n",
    "        if i == n_subplots // 2:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        # Don't add legend here - can be added outside function if needed\n",
    "\n",
    "        # Style axes\n",
    "        ax.tick_params(colors='#4a4a4a', width=0.5, length=2)\n",
    "        ax.spines['left'].set_color('#4a4a4a')\n",
    "        ax.spines['left'].set_linewidth(0.5)\n",
    "        ax.spines['bottom'].set_color('#4a4a4a')\n",
    "        ax.spines['bottom'].set_linewidth(0.5)\n",
    "        ax.xaxis.label.set_color('#4a4a4a')\n",
    "        ax.yaxis.label.set_color('#4a4a4a')\n",
    "        ax.set_facecolor(\"none\")\n",
    "        ax.minorticks_off()\n",
    "    # Only add xlabel to the bottom subplot\n",
    "    if xlabel is not None:\n",
    "        axes[-1].set_xlabel(xlabel)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    # Set same y-limits for all subplots\n",
    "    # Find the maximum y-limit across all subplots\n",
    "    max_ylim = 0\n",
    "    for ax in axes:\n",
    "        current_ylim = ax.get_ylim()[1]\n",
    "        max_ylim = max(max_ylim, current_ylim)\n",
    "    # Apply the same y-limit to all subplots\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(0, max_ylim)\n",
    "        ax.set_yticks([0, np.round(max_ylim*.7/10)*10])\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ecde4",
   "metadata": {},
   "outputs": [],
   "source": "# === MEAN METRICS PER CAMPAIGN ===\n\nmean_sbert_session_creat = np.zeros(len(sbert_session_creativity))\nmean_cohesion_session = np.zeros(len(cohesion_session_scores))\nmean_sbert_post_distances = np.zeros(len(sbert_post_distances))\n\nfor i in range(len(campaign_names)):\n    mean_sbert_session_creat[i] = np.mean(sbert_session_creativity[i])\n    mean_cohesion_session[i] = np.mean(cohesion_session_scores[i])\n    mean_sbert_post_distances[i] = np.nanmean(sbert_post_distances[i])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea96d1c",
   "metadata": {},
   "outputs": [],
   "source": "# Single histogram of mean values per campaign\nplt.rcParams.update({'font.size': 8})\n\nplot_histogram(mean_sbert_session_creat,\n               figsize=(2, 1.5),\n               bins=40,\n               alpha=0.8,\n               xlabel=r'$\\mathbf{Creativity\\ 1}$' + '\\nsession semantic diversity')\nplt.tight_layout()\nplt.savefig('creativity1.pdf', transparent=True)\n\nplot_histogram(mean_sbert_post_distances,\n               ylabel=\"   \",\n               figsize=(2, 1.5),\n               bins=40,\n               alpha=0.8,\n               xlabel=r'$\\mathbf{Creativity\\ 2}$' + '\\nsequential semantic shift')\nplt.tight_layout()\nplt.savefig('creativity2.pdf', transparent=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389211b",
   "metadata": {},
   "outputs": [],
   "source": "# === COMBINED HISTOGRAMS (All Data) ===\n\ntime_intervals_all = np.concatenate(time_intervals_data)\npost_lengths_all = np.concatenate(post_len_data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef48085",
   "metadata": {},
   "outputs": [],
   "source": "plot_histogram(time_intervals_all,\n               figsize=(3, 1.5),\n               log_y=True,\n               bins=70,\n               colors=[[.4, 0.57, .18]],\n               alpha=0.7,\n               log_bins=True,\n               xlabel='Time between posts (h)')\nplt.tight_layout()\nplt.savefig('time_intervals.pdf', transparent=True)\n\nplot_histogram(post_lengths_all,\n               colors=[[.4, 0.57, .18]],\n               figsize=(3, 1.5),\n               alpha=0.7,\n               ylabel=\"   \",\n               log_y=True,\n               bins=70,\n               log_bins=True,\n               xlabel='Post length (# words)')\nplt.tight_layout()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886759c",
   "metadata": {},
   "outputs": [],
   "source": "# === VISUALIZATION (Aggregated by Category) ===\n\n# Define category display order (must match format from categorize_campaigns)\nCATEGORY_ORDER = [\n    'human',\n    'model:gemini-1.5-pro, include_player_personalities:False',\n    'model:gemini-1.5-pro, include_player_personalities:True',\n    'model:claude-3-7-sonnet-latest, include_player_personalities:False',\n    'model:claude-3-7-sonnet-latest, include_player_personalities:True',\n    'model:gpt-4o, include_player_personalities:False',\n    'model:gpt-4o, include_player_personalities:True',\n]\n\n# Aggregate by category\npost_len_agg, _ = aggregate_by_category(post_len_data, campaign_names, categories, CATEGORY_ORDER)\ncohesion_agg, _ = aggregate_by_category(cohesion_session_scores, campaign_names, categories, CATEGORY_ORDER)\ncreativity_1_agg, _ = aggregate_by_category(sbert_session_creativity, campaign_names, categories, CATEGORY_ORDER)\ncreativity_2_agg, _ = aggregate_by_category(sbert_post_distances, campaign_names, categories, CATEGORY_ORDER)\n\n# Check category sizes\nprint(\"Aggregated category sizes:\")\nfor i, cat in enumerate(CATEGORY_ORDER):\n    print(f\"  {cat}: {len(post_len_agg[i])} data points\")\n\nplt.rcParams.update({'font.size': 8})\n\n# Post length comparison\nplot_comparison_histograms(\n    post_len_agg,\n    bins=20,\n    log_bins=True,\n    log_y=False,\n    xlabel=r'$\\mathbf{Post\\ length}$' + '\\n(# words)',\n    figsize=(2.1, 4))\nplt.tight_layout()\nplt.subplots_adjust(hspace=0)\nplt.savefig('human_vs_llm_len.pdf', transparent=True)\n\n# Cohesion comparison\nplot_comparison_histograms(\n    cohesion_agg,\n    bins=20,\n    log_bins=False,\n    ylabel=\" \",\n    xlabel=r'$\\mathbf{Cohesion}$' + '\\nJaccard similarity',\n    figsize=(2.1, 4))\nplt.tight_layout()\nplt.subplots_adjust(hspace=0)\nplt.savefig('human_vs_llm_cohesion.pdf', transparent=True)\n\n# Creativity 1 comparison\nplot_comparison_histograms(\n    creativity_1_agg,\n    bins=20,\n    log_bins=False,\n    ylabel=\" \",\n    xlabel=r'$\\mathbf{Creativity\\ 1}$' + '\\nsession semantic diversity',\n    figsize=(2.1, 4))\nplt.tight_layout()\nplt.subplots_adjust(hspace=0)\nplt.savefig('human_vs_llm_creativity.pdf', transparent=True)\n\n# Creativity 2 comparison\nplot_comparison_histograms(\n    creativity_2_agg,\n    bins=20,\n    log_bins=False,\n    ylabel=\" \",\n    xlabel=r'$\\mathbf{Creativity\\ 2}$' + '\\nSequential Semantic Shift',\n    figsize=(2.1, 4))\nplt.tight_layout()\nplt.subplots_adjust(hspace=0)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}